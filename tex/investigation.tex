\section{Investigation}
\label{sec:investigation}
We now use POSE to investigate the CPU power consumption of codes taken from the Mantevo~\cite{heroux:2009aa} and Rodinia~\cite{che:2009aa} application suites.
The applications we study are all simplified versions of production codes intended for research purposes.
As such they exhibit relatively compact code bases and well understood behaviours while still providing represantative workloads.

CPU power consumption accounts for a significant portion of the energy used by high performance systems~\cite{rong:2010aa}, making it a prime candidate for optimisation.
Crucially for POSE, this variety of power consumption can be accurately measured on unmodified comodity hardware~\cite{hackenberg:2013aa}.

\subsection{CPU Power Consumption}
\label{ssec:cpupower}
Modern processors rely on Complimentary Metal Oxide Semiconductor (CMOS) technology.
\autoref{eq:totpwr} separates the power draw of CMOS chips into its component parts, of which dynamic power and leakage power are most significant.
\begin{equation}
\label{eq:totpwr}
P_{tot} = P_{dyn} + P_{leak} + P_{other}
\end{equation}
Dynamic power is consumed when logic gates change state as a processor performs work. 
Leakage power exists because at microscopic scales the insulating properties of silicon break down, allowing some current to escape even when gates remain inactive.
Other forms of power dissipation exist, however their effects are relatively minor \cite{kaxiras:2008aa}.
\begin{gather}
P_{dyn} \propto CV^{2}Af \label{eq:dynpwr} \\
P_{leak} = V \times I_{leak} \label{eq:staticpwr} \\
P_{tot} \propto CV^{2}Af + VI_{leak} \label{eq:totpwr2} 
\end{gather}
\autoref{eq:dynpwr} is a common approximation for dynamic power in which $C$ denotes load capacitance, $V$ the supply voltage, $A$ the activity factor and $f$ the clock frequency. 
\autoref{eq:staticpwr} is a simplified expression for leakage power that exploits the fact that leakage current $I_{leak}$ is invariant to processor workload~\cite{kim:2003aa}.
Substituting these into \autoref{eq:totpwr} yields the parametrised expression for total power consumption given in \autoref{eq:totpwr2} in which all terms except frequency, voltage and activity factor are constants.

Activity factor captures the fraction of logic elements which change state each clock cycle.
Frequency and supply voltage vary in tandem, taking values from a fixed set of $(frequency, voltage)$ pairs known as P-States.
Dynamic Voltage and Frequency Scaling (DVFS) selects the most appropriate P-State for the current workload.
Finally, capacitance and leakage current are constants dictated by processor design.

Processor architecture also plays a significant roll in determining total power consumption.
Each core in a multicore architecture operates independantly with its own activity factor and P-State.
As a result, \autoref{eq:totpwr2} should be summed across all cores to arrive at a value for the entire processor.

\subsection{Feasible Performance Envelope}
When applying POSE the first step is to construct an appropriate feasible performance envelope.
Processor manufacturers usually supply power consumption envelopes for their hardware, however these tend to be conservative estimates.
POSE works best when the maximum and minimum power bounds are as tight as possible, so instead we determine $P_{\alpha}$ and $P_{\beta}$ empirically. 

The properties we must account for when developing benchmarks for $P_{\alpha}$ and $P_{\beta}$ are P-State, activity factor and the number of cores active.
Of these, P-State is the easiest 

\clearpage


We define the range of values that activity factor can take while running a code as $[\alpha,~\beta]$ where $0 < \alpha < \beta < 1$. These values are a function of hardware design and for multi-core systems the number of cores active.


\todo{Flesh this out into some sort of abstract methodology.}
As previously discussed, activity factor and P-state are the only properties through which code (and hence performance engineers) can influence power consumption.
We use the \texttt{cpufrequtils} package to override DVFS and manually set the desired P-states, leaving only activity factor to consider.

\begin{figure}[ht]                                                               
\centering                                                                      
\lstset{basicstyle=\ttfamily\footnotesize\bfseries, frame=tb} %small bold text, lines top and bottom 
\lstinputlisting[]{lst/alpha_benchmark.c}              
\caption{Baseline Power Micro-Benchmark}                            
\label{fig:microbench}                                                           
\end{figure}  

Our benchmark for activity factor $\alpha$ is given in \autoref{fig:microbench}.
It repeatedly executes a single \texttt{jmp} instruction, performing no computation or memory accesses in the process.
We assert that non-trivial computational workloads exhibit strictly higher activity factors than this minimal micro-benchmark.
The only exceptions are applications which spend so long blocked waiting for resources they allow the processor to enter idle states.
If necessary this behaviour can be captured by adding corresponding delays to the benchmark.

We evaluated three codes
Prime95 and Linpack are two codes frequently used to stress-test CPU power consumption.

We also evaluated Prime95 and Linpack as potential $P_{\beta}$ benchmarks


before settling on FIRESTARTER.

FIRESTARTER~\cite{hackenberg:2013ab}, a tool designed to trigger near-peak power consumption in a range of x86\_64 processors.

compute nodes.

FIRESTARTER, `a simple yet versatile tool that generates near-peak power consumption of compute nodes'.
We evaluated several stress test tools in order to benchmark $P_{\beta}$ before we settled on
FIRESTARTER, which is 
We use FIRESTARTER, a benchmark

\begin{enumerate}
  \item \todo{(Abstract) Methodology - say we just measure for $\{freq\} \times \{cores\}$}
  \item \todo{FIRESTARTER $\beta$ paragraph}
  \item \todo{Experimental Setup}
  \begin{enumerate}
    \item \todo{Get hardware deets from camelot}
  \end{enumerate}
  \item \todo{Write up results}
  \item \todo{Bosh out freq comparison waffle}
\end{enumerate}


\todo{WORKING POINT}

Linpack is characterised by its extremely high code intensity. 
\todo{false baselines etc}
This highlights the fact that effective use of POSE depends largely on the choice of roofline and 


\begin{table}
\centering
\caption{Early Investigation}
\input{tab/tex/code_metrics.tex}
\end{table} 



  \begin{table}
    \setlength{\tabcolsep}{.5em}
    \caption{Code POSE Values}
    \begin{subtable}{\textwidth}
    \centering
    \caption{Time (s)}
    \input{tab/tex/code_pose_time.tex}
    \end{subtable} 
    \begin{subtable}{\textwidth}
    \centering
    \caption{Energy (J)}
    \input{tab/tex/code_pose_energy.tex}
    \end{subtable}
    \label{tab:pose_params}
  \end{table} 



\subsection{Experimental Methodology}
CPU energy consumption was measured using Intel's Running Average Power Limit (RAPL) technology~\cite{david:2010aa}.
We created a simple tool babsed on the Unix \texttt{time} which output energy consumption figures as well as conventional runtime figures.
The techniques described in \cite{hahnel:2012aa} were used to ensure measurement accuracy. 

\todo{Detail app arguments etc.}


\todo{consider each in turn as a potential source of optimisations.}
%TODO make sure this is explicitly Linpack table in text
\begin{table}
\centering
\caption{Feasible Performance Envelope Parameters (W)}
\input{tab/tex/fpe_params.tex}
\end{table} 

\begin{figure}[t]%
  \providecommand{\plotwidth}{.95\linewidth}
  \begin{subfigure}[t]{.5\linewidth}%
    \input{plot/minimd-investigation/plot_core}%
    \caption{MiniMD}%
  \end{subfigure}%
  \begin{subfigure}[t]{.5\linewidth}%
    \input{plot/lavamd-investigation/plot_core}%
    \caption{LavaMD}%
  \end{subfigure}%
  \begin{center}%
    \ref{minimd:legend}%
  \end{center}%
  \caption{$E^1t^2$ POSE for Activity Factor Optimisation}%
  \label{fig:minimd}%
\end{figure}

\begin{figure}[t]%
\begin{subfigure}[t]{.5\linewidth}%
\centering%
\input{plot/minimd-pstates/plot_core}%
\caption{MiniMD}%
\end{subfigure}%
\begin{subfigure}[t]{.5\linewidth}%
\input{plot/lavamd-pstates/plot_core}%
\caption{LavaMD}%
\end{subfigure}%
\begin{center}%
\ref{minimd-pstate:legend}%
\end{center}%
\caption{$E^1t^2$ POSE for P-State Optimisation}%
\label{fig:pstates}%
\end{figure}%

Changes in processor P-State do not effect code performance linearly due to system bottlenecks. Critical path? \todo{is there a smart term for this? Bound and bottleneck analysis.} A modern super-scalar CPU contains many specialized functional units. A code which is bottlenecked by Memory accesses may when slowed dow.

A code with low operational intensity 


\subsection{Results}


\autoref{tab:pose_params} \todo{reword given central table} shows that for MiniMD, the longest runtime within the Power Optimized Software Envelope is 30.70s.
This means that any optimization which trades increased runtime for improved power efficiency can slow MiniMD down by at most 0.41s before $E^1t^2$ becomes strictly worse.
The upper limit of energy to be saved from power optimisation alone for MiniMD running on our target platform is is 32.82J.
The lowest value of $E^1t^2$ within the envelope is 718232.78, an improvement of 7.60\% over the baseline code. 
Runtime optimization will be required to deliver any improvements above this level.
We also know that a speedup of, 1.16x, or 4.16s, is guaranteed to beat $\theta$ in terms of $E^1t^2$.
Finally, a speedup of 1.19x, or 4.84s, is guaranteed to beat any power optimised version of $\theta$ in terms of $E^1t^2$

\autoref{tab:pose_params} \todo{reword given central} shows that for LavaMD, the longest runtime within the Power Optimized Software Envelope as 69.76s.
This means that any optimization which trades increased runtime for improved power efficiency can slow LavaMD down by at most 4.12s before $E^1t^2$ becomes strictly worse.
The upper limit of energy to be saved from power optimization alone is 353.36J.
The lowest value of $E^1t^2$ within the envelope is 6332608.91, an improvement of 30.59\% over the baseline code.
Runtime optimization will be required to deliver any improvements above this level.
We also know that a speedup of 1.11x, or 6.26s, is guaranteed to beat $\theta$ in terms of $E^1t^2$.
Finally, a runtime optimisation of 1.25x, or 13.06s, is guaranteed to beat any power optimised version of $\theta$ in terms of $E^1t^2$ 

\subsection{Discussion}

\todo{both in absolute terms and as a percentage of the baseline}

The figures produced by POSE are all upper bounds, and the benefits of power optimisation will be more modest in practice. Even so, these figures are useful as they allow performance engineers to make informed decisions about where best to focus their efforts. If they consider a $1.03 \times$ speed up to be more achievable than up to the maximum $1.17\times$ reduction in activity factor then they can proceed to apply conventional optimisations safe in the knowledge that overall performance will improve despite any increases in activity factor.

If a performance engineer decides the benefits of power optimisation are worth pursuing after applying POSE, the question still remains as to how he should go about searching for those optimisations.
